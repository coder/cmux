{"version":3,"file":"providerOptions.js","sourceRoot":"","sources":["../../../src/utils/ai/providerOptions.ts"],"names":[],"mappings":";AAAA;;;;GAIG;;AA+BH,oDAkGC;AA5HD,+CAAuF;AACvF,wCAAqC;AAWrC;;;;;;;;;;;;;GAaG;AACH,SAAgB,oBAAoB,CAClC,WAAmB,EACnB,aAA4B,EAC5B,QAAwB;IAExB,mCAAmC;IACnC,MAAM,CAAC,QAAQ,CAAC,GAAG,WAAW,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IAE1C,SAAG,CAAC,KAAK,CAAC,sBAAsB,EAAE;QAChC,WAAW;QACX,QAAQ;QACR,aAAa;KACd,CAAC,CAAC;IAEH,IAAI,CAAC,QAAQ,EAAE,CAAC;QACd,SAAG,CAAC,KAAK,CAAC,0DAA0D,CAAC,CAAC;QACtE,OAAO,EAAE,CAAC;IACZ,CAAC;IAED,mCAAmC;IACnC,IAAI,QAAQ,KAAK,WAAW,EAAE,CAAC;QAC7B,MAAM,YAAY,GAAG,qCAA0B,CAAC,aAAa,CAAC,CAAC;QAC/D,SAAG,CAAC,KAAK,CAAC,wCAAwC,EAAE;YAClD,YAAY;YACZ,aAAa;SACd,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,SAAS,EAAE;gBACT,sBAAsB,EAAE,KAAK,EAAE,0CAA0C;gBACzE,aAAa,EAAE,IAAI,EAAE,yDAAyD;gBAC9E,2CAA2C;gBAC3C,GAAG,CAAC,YAAY,GAAG,CAAC,IAAI;oBACtB,QAAQ,EAAE;wBACR,IAAI,EAAE,SAAS;wBACf,YAAY;qBACb;iBACF,CAAC;aACH;SACF,CAAC;QACF,SAAG,CAAC,IAAI,CAAC,mDAAmD,EAAE,OAAO,CAAC,CAAC;QACvE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,gCAAgC;IAChC,IAAI,QAAQ,KAAK,QAAQ,EAAE,CAAC;QAC1B,MAAM,eAAe,GAAG,kCAAuB,CAAC,aAAa,CAAC,CAAC;QAE/D,yEAAyE;QACzE,IAAI,kBAAsC,CAAC;QAC3C,IAAI,QAAQ,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YACpC,8BAA8B;YAC9B,KAAK,IAAI,CAAC,GAAG,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC9C,IAAI,QAAQ,CAAC,CAAC,CAAC,CAAC,IAAI,KAAK,WAAW,EAAE,CAAC;oBACrC,MAAM,QAAQ,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAE,gBAAgB,CAAC;oBACxD,IAAI,QAAQ,IAAI,QAAQ,IAAI,QAAQ,EAAE,CAAC;wBACrC,MAAM,UAAU,GAAG,QAAQ,CAAC,MAA6C,CAAC;wBAC1E,kBAAkB,GAAG,UAAU,EAAE,UAAgC,CAAC;oBACpE,CAAC;oBACD,IAAI,kBAAkB,EAAE,CAAC;wBACvB,SAAG,CAAC,KAAK,CAAC,gDAAgD,EAAE,EAAE,kBAAkB,EAAE,CAAC,CAAC;wBACpF,MAAM;oBACR,CAAC;gBACH,CAAC;YACH,CAAC;QACH,CAAC;QAED,SAAG,CAAC,KAAK,CAAC,qCAAqC,EAAE;YAC/C,eAAe;YACf,aAAa;YACb,kBAAkB;SACnB,CAAC,CAAC;QAEH,MAAM,OAAO,GAAoB;YAC/B,MAAM,EAAE;gBACN,iBAAiB,EAAE,IAAI,EAAE,0CAA0C;gBACnE,oCAAoC;gBACpC,WAAW,EAAE,UAAU,EAAE,gDAAgD;gBACzE,4CAA4C;gBAC5C,GAAG,CAAC,eAAe,IAAI;oBACrB,eAAe;oBACf,gBAAgB,EAAE,UAAU,EAAE,sCAAsC;oBACpE,8FAA8F;oBAC9F,4EAA4E;oBAC5E,gFAAgF;oBAChF,OAAO,EAAE,CAAC,6BAA6B,CAAC;iBACzC,CAAC;gBACF,6DAA6D;gBAC7D,GAAG,CAAC,kBAAkB,IAAI,EAAE,kBAAkB,EAAE,CAAC;aAClD;SACF,CAAC;QACF,SAAG,CAAC,IAAI,CAAC,gDAAgD,EAAE,OAAO,CAAC,CAAC;QACpE,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,yDAAyD;IACzD,SAAG,CAAC,KAAK,CAAC,4CAA4C,EAAE,QAAQ,CAAC,CAAC;IAClE,OAAO,EAAE,CAAC;AACZ,CAAC","sourcesContent":["/**\n * Provider options builder for AI SDK\n *\n * Converts unified thinking levels to provider-specific options\n */\n\nimport type { AnthropicProviderOptions } from \"@ai-sdk/anthropic\";\nimport type { OpenAIResponsesProviderOptions } from \"@ai-sdk/openai\";\nimport type { ThinkingLevel } from \"@/types/thinking\";\nimport { ANTHROPIC_THINKING_BUDGETS, OPENAI_REASONING_EFFORT } from \"@/types/thinking\";\nimport { log } from \"@/services/log\";\nimport type { CmuxMessage } from \"@/types/message\";\n\n/**\n * Provider-specific options structure for AI SDK\n */\ntype ProviderOptions =\n  | { anthropic: AnthropicProviderOptions }\n  | { openai: OpenAIResponsesProviderOptions }\n  | Record<string, never>; // Empty object for unsupported providers\n\n/**\n * Build provider-specific options for AI SDK based on thinking level\n *\n * This function configures provider-specific options for supported providers:\n * 1. Enable reasoning traces (transparency into model's thought process)\n * 2. Set reasoning level (control depth of reasoning based on task complexity)\n * 3. Enable parallel tool calls (allow concurrent tool execution)\n * 4. Extract previousResponseId for OpenAI persistence (when available)\n *\n * @param modelString - Full model string (e.g., \"anthropic:claude-opus-4-1\")\n * @param thinkingLevel - Unified thinking level\n * @param messages - Conversation history to extract previousResponseId from\n * @returns Provider options object for AI SDK\n */\nexport function buildProviderOptions(\n  modelString: string,\n  thinkingLevel: ThinkingLevel,\n  messages?: CmuxMessage[]\n): ProviderOptions {\n  // Parse provider from model string\n  const [provider] = modelString.split(\":\");\n\n  log.debug(\"buildProviderOptions\", {\n    modelString,\n    provider,\n    thinkingLevel,\n  });\n\n  if (!provider) {\n    log.debug(\"buildProviderOptions: No provider found, returning empty\");\n    return {};\n  }\n\n  // Build Anthropic-specific options\n  if (provider === \"anthropic\") {\n    const budgetTokens = ANTHROPIC_THINKING_BUDGETS[thinkingLevel];\n    log.debug(\"buildProviderOptions: Anthropic config\", {\n      budgetTokens,\n      thinkingLevel,\n    });\n\n    const options: ProviderOptions = {\n      anthropic: {\n        disableParallelToolUse: false, // Always enable concurrent tool execution\n        sendReasoning: true, // Include reasoning traces in requests sent to the model\n        // Conditionally add thinking configuration\n        ...(budgetTokens > 0 && {\n          thinking: {\n            type: \"enabled\",\n            budgetTokens,\n          },\n        }),\n      },\n    };\n    log.info(\"buildProviderOptions: Returning Anthropic options\", options);\n    return options;\n  }\n\n  // Build OpenAI-specific options\n  if (provider === \"openai\") {\n    const reasoningEffort = OPENAI_REASONING_EFFORT[thinkingLevel];\n\n    // Extract previousResponseId from last assistant message for persistence\n    let previousResponseId: string | undefined;\n    if (messages && messages.length > 0) {\n      // Find last assistant message\n      for (let i = messages.length - 1; i >= 0; i--) {\n        if (messages[i].role === \"assistant\") {\n          const metadata = messages[i].metadata?.providerMetadata;\n          if (metadata && \"openai\" in metadata) {\n            const openaiData = metadata.openai as Record<string, unknown> | undefined;\n            previousResponseId = openaiData?.responseId as string | undefined;\n          }\n          if (previousResponseId) {\n            log.debug(\"buildProviderOptions: Found previousResponseId\", { previousResponseId });\n            break;\n          }\n        }\n      }\n    }\n\n    log.debug(\"buildProviderOptions: OpenAI config\", {\n      reasoningEffort,\n      thinkingLevel,\n      previousResponseId,\n    });\n\n    const options: ProviderOptions = {\n      openai: {\n        parallelToolCalls: true, // Always enable concurrent tool execution\n        // TODO: allow this to be configured\n        serviceTier: \"priority\", // Always use priority tier for best performance\n        // Conditionally add reasoning configuration\n        ...(reasoningEffort && {\n          reasoningEffort,\n          reasoningSummary: \"detailed\", // Enable detailed reasoning summaries\n          // Include reasoning encrypted content to preserve reasoning context across conversation steps\n          // Required when using reasoning models (gpt-5, o3, o4-mini) with tool calls\n          // See: https://sdk.vercel.ai/providers/ai-sdk-providers/openai#responses-models\n          include: [\"reasoning.encrypted_content\"],\n        }),\n        // Include previousResponseId for persistence (Responses API)\n        ...(previousResponseId && { previousResponseId }),\n      },\n    };\n    log.info(\"buildProviderOptions: Returning OpenAI options\", options);\n    return options;\n  }\n\n  // No provider-specific options for unsupported providers\n  log.debug(\"buildProviderOptions: Unsupported provider\", provider);\n  return {};\n}\n"]}
{"version":3,"file":"chatStats.js","sourceRoot":"","sources":["../../src/types/chatStats.ts"],"names":[],"mappings":"","sourcesContent":["import type { ChatUsageDisplay } from \"@/utils/tokens/tokenStatsCalculator\";\n\nexport interface TokenConsumer {\n  name: string; // \"User\", \"Assistant\", \"bash\", \"readFile\", etc.\n  tokens: number; // Total token count for this consumer\n  percentage: number; // % of total tokens\n  fixedTokens?: number; // Fixed overhead (e.g., tool definitions)\n  variableTokens?: number; // Variable usage (e.g., actual tool calls, text)\n}\n\nexport interface ChatStats {\n  consumers: TokenConsumer[]; // Sorted descending by token count\n  totalTokens: number;\n  model: string;\n  tokenizerName: string; // e.g., \"Anthropic Claude\", \"OpenAI GPT-4\"\n  usageHistory: ChatUsageDisplay[]; // Ordered array of actual usage statistics from API responses\n}\n"]}